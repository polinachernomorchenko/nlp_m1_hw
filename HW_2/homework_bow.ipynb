{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20f786e",
   "metadata": {},
   "source": [
    "# Домашнее задание № 2. Мешок слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from razdel import tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import nltk\n",
    "from pymorphy2 import MorphAnalyzer\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "stopwords = nltk.corpus.stopwords.words(\"russian\")\n",
    "pymorphy = MorphAnalyzer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf72d19",
   "metadata": {},
   "source": [
    "## Задание 1 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a045e99",
   "metadata": {},
   "source": [
    "У векторайзеров в sklearn есть встроенная токенизация на регулярных выражениях. Найдите способо заменить её на кастомную токенизацию"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4d453",
   "metadata": {},
   "source": [
    "Обучите векторайзер с дефолтной токенизацией и с токенизацией razdel.tokenize. Обучите классификатор (любой) с каждым из векторизаторов. Сравните метрики и выберете победителя. \n",
    "\n",
    "(в вашей тетрадке должен быть код обучения и все метрики; если вы сдаете в .py файлах то сохраните полученные метрики в отдельном файле или в комментариях)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def razdel_tokenize_wrapper(text, *args, **kwargs):\n",
    "    tokens = tokenize(text, *args, **kwargs)\n",
    "    return [token.text for token in tokens]\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"labeled.csv\")\n",
    "X, y = data.comment, data.toxic\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "default_vectorizer = TfidfVectorizer()\n",
    "razdel_vectorizer = TfidfVectorizer(tokenizer=razdel_tokenize_wrapper)\n",
    "\n",
    "lr_default = LogisticRegression()\n",
    "lr_razdel = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_train = default_vectorizer.fit_transform(X_train)\n",
    "razdel_train = razdel_vectorizer.fit_transform(X_train)\n",
    "\n",
    "lr_default.fit(default_train, y_train)\n",
    "lr_razdel.fit(razdel_train, y_train)\n",
    "\n",
    "default_preds = lr_default.predict(default_vectorizer.transform(X_test))\n",
    "razdel_preds = lr_razdel.predict(razdel_vectorizer.transform(X_test))\n",
    "\n",
    "default_f1 = f1_score(default_preds, y_test)\n",
    "razdel_f1 = f1_score(razdel_preds, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "default tokenizer f1: 0.6722173531989483\n",
      "razdel tokenizer f1: 0.691947166595654\n"
     ]
    }
   ],
   "source": [
    "print(f\"default tokenizer f1: {default_f1}\")\n",
    "print(f\"razdel tokenizer f1: {razdel_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9076e",
   "metadata": {},
   "source": [
    "## Задание 2 (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e25357",
   "metadata": {},
   "source": [
    "Обучите 2 любых разных классификатора из семинара. Предскажите токсичность для текстов из тестовой выборки (используйте одну и ту же выборку для обоих классификаторов) и найдите 10 самых токсичных для каждого из классификаторов. Сравните получаемые тексты - какие тексты совпадают, какие отличаются, правда ли тексты токсичные?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7de962ad",
   "metadata": {},
   "source": [
    "Требования к моделям:   \n",
    "а) один классификатор должен использовать CountVectorizer, другой TfidfVectorizer  \n",
    "б) у векторазера должны быть вручную заданы как минимум 5 параметров (можно ставить разные параметры tfidfvectorizer и countvectorizer)  \n",
    "в) у классификатора должно быть задано вручную как минимум 2 параметра (по возможности)  \n",
    "г)  f1 мера каждого из классификаторов должна быть минимум 0.75  \n",
    "\n",
    "*random_seed не считается за параметр"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(text):\n",
    "    tokens = razdel_tokenize_wrapper(text)\n",
    "    lemmas = [\n",
    "        lemma\n",
    "        for word in tokens\n",
    "        if (lemma := pymorphy.parse(word)[0].normal_form) not in stopwords\n",
    "    ]\n",
    "\n",
    "    return \" \".join(lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic\n",
       "0.0    9586\n",
       "1.0    4826\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.toxic.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = data[data.toxic == 1]\n",
    "non_toxic = data[data.toxic == 0][: len(toxic)]\n",
    "balanced_data = pd.concat([toxic, non_toxic])\n",
    "\n",
    "X, y = balanced_data.comment, balanced_data.toxic\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Random forest + TfidfVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_tfidf = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    max_df=0.8,\n",
    "    min_df=3,\n",
    "    ngram_range=(1, 2),\n",
    "    preprocessor=preprocessing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec = vec_tfidf.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=120, max_features=0.2)\n",
    "random_forest.fit(X_vec, y_train)\n",
    "X_test_vec = vec_tfidf.transform(X_test)\n",
    "forest_preds = random_forest.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.74      0.75      1450\n",
      "         1.0       0.75      0.75      0.75      1446\n",
      "\n",
      "    accuracy                           0.75      2896\n",
      "   macro avg       0.75      0.75      0.75      2896\n",
      "weighted avg       0.75      0.75      0.75      2896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(forest_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. LogReg + CountVec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_count = CountVectorizer(\n",
    "    max_features=10000,\n",
    "    max_df=0.7,\n",
    "    min_df=10,\n",
    "    ngram_range=(1, 1),\n",
    "    preprocessor=preprocessing,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_vec = vec_count.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(penalty=\"l1\", max_iter=500, solver=\"liblinear\")\n",
    "lr.fit(X_vec, y_train)\n",
    "X_test_vec = vec_count.transform(X_test)\n",
    "lr_preds = lr.predict(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.81      0.78      1343\n",
      "         1.0       0.82      0.77      0.80      1553\n",
      "\n",
      "    accuracy                           0.79      2896\n",
      "   macro avg       0.79      0.79      0.79      2896\n",
      "weighted avg       0.79      0.79      0.79      2896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(lr_preds, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f228c3e",
   "metadata": {},
   "source": [
    "## Задание 3 (4 балла - 1 балл за каждый классификатор)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "566929b7",
   "metadata": {},
   "source": [
    "Для классификаторов Logistic Regression, Decision Trees, Naive Bayes, RandomForest найдите способ извлечь важность признаков для предсказания токсичного класса. Сопоставьте полученные числа со словами (или нграммами) в словаре и найдите топ - 5 \"токсичных\" слов для каждого из классификаторов. \n",
    "\n",
    "Важное требование: в топе не должно быть стоп-слов. Для этого вам нужно будет правильным образом настроить векторизацию. \n",
    "Также как и в предыдущем задании у классификаторов должно быть задано вручную как минимум 2 параметра (по возможности, f1 мера каждого из классификаторов должна быть минимум 0.75"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "81f86878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top5_toxic(coefs):\n",
    "    vocab = vec_count.get_feature_names_out()\n",
    "    top5_indexes = np.argsort(-coefs)[:5]\n",
    "    top_5_toxic_words = [vocab[i] for i in top5_indexes]\n",
    "    print(\"\\n\".join(top_5_toxic_words))\n",
    "\n",
    "\n",
    "def print_top5_toxic_tree(tree):\n",
    "    train_predictions = tree.predict(X_vec)\n",
    "    toxic_features = []\n",
    "    non_toxic_features = []\n",
    "    vocab = vec_count.get_feature_names_out()\n",
    "    features_importance = tree.feature_importances_\n",
    "    top_50_candidates = np.argsort(-features_importance)[:50].tolist()\n",
    "\n",
    "    while len(toxic_features) < 5:\n",
    "        current_feat = top_50_candidates.pop(0)\n",
    "        toxic_cr = 0\n",
    "        non_toxic_cr = 0\n",
    "        for i in range(len(train_predictions)):\n",
    "            feat_value = X_vec[i, current_feat]\n",
    "            # 0.5 порог на всех разбиениях (я посмотрела на картинку дерева)\n",
    "            if feat_value >= 0.5:\n",
    "                if train_predictions[i] == 0:\n",
    "                    non_toxic_cr += 1\n",
    "                else:\n",
    "                    toxic_cr += 1\n",
    "\n",
    "        target_list = toxic_features if toxic_cr > non_toxic_cr else non_toxic_features\n",
    "        target_list.append(current_feat)\n",
    "\n",
    "    toxic_words_tree = [vocab[i] for i in toxic_features]\n",
    "    print(\"\\n\".join(toxic_words_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "дебил\n",
      "хохол\n",
      "рашка\n",
      "вон\n",
      "дегенерат\n"
     ]
    }
   ],
   "source": [
    "# lr from 2 section\n",
    "print_top5_toxic(lr.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.75      0.71      0.73      1510\n",
      "         1.0       0.70      0.74      0.72      1386\n",
      "\n",
      "    accuracy                           0.73      2896\n",
      "   macro avg       0.73      0.73      0.73      2896\n",
      "weighted avg       0.73      0.73      0.73      2896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeClassifier(\n",
    "    criterion=\"log_loss\", min_samples_leaf=3, max_features=\"sqrt\"\n",
    ")\n",
    "tree.fit(X_vec, y_train)\n",
    "tree_preds = tree.predict(X_test_vec)\n",
    "print(classification_report(tree_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хохлов\n",
      "дебил\n",
      "хохол\n",
      "тред\n",
      "тупой\n"
     ]
    }
   ],
   "source": [
    "print_top5_toxic_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.67      0.76      0.71      1260\n",
      "         1.0       0.80      0.71      0.75      1636\n",
      "\n",
      "    accuracy                           0.73      2896\n",
      "   macro avg       0.73      0.74      0.73      2896\n",
      "weighted avg       0.74      0.73      0.73      2896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=130, max_depth=25)\n",
    "rf.fit(X_vec, y_train)\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=130, max_depth=25, criterion=\"log_loss\", max_features=\"sqrt\"\n",
    ")\n",
    "rf.fit(X_vec, y_train)\n",
    "rf_preds = rf.predict(X_test_vec)\n",
    "print(classification_report(rf_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "хохол\n",
      "хохлов\n",
      "тупой\n",
      "нахуй\n",
      "блядь\n"
     ]
    }
   ],
   "source": [
    "print_top5_toxic_tree(rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.62      0.86      0.72      1035\n",
      "         1.0       0.90      0.70      0.79      1861\n",
      "\n",
      "    accuracy                           0.76      2896\n",
      "   macro avg       0.76      0.78      0.75      2896\n",
      "weighted avg       0.80      0.76      0.76      2896\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nb = BernoulliNB(alpha=0.001, class_prior=[0.5, 0.5])\n",
    "nb.fit(X_vec.toarray(), y_train)\n",
    "nb_preds = nb.predict(X_test_vec.toarray())\n",
    "print(classification_report(nb_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "это\n",
      "всё\n",
      "свой\n",
      "весь\n",
      "ещё\n"
     ]
    }
   ],
   "source": [
    "print_top5_toxic(nb.feature_log_prob_[1, :])  # стоп-слова из нлтк не прокатили (("
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
